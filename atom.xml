<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Adversarial Thinking]]></title>
  <link href="http://adversari.es//atom.xml" rel="self"/>
  <link href="http://adversari.es//"/>
  <updated>2013-09-12T01:14:26-04:00</updated>
  <id>http://adversari.es//</id>
  <author>
    <name><![CDATA[Christian Ternus]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    
    <title type="html"><![CDATA[Slouching towards the Panopticon]]></title>
    <link href="http://adversari.es//blog/2013/09/11/slouching-towards-the-panopticon/"/>
    
    <updated>2013-09-11T21:19:00-04:00</updated>
    <id>http://adversari.es//blog/2013/09/11/slouching-towards-the-panopticon</id>
    
    <content type="html"><![CDATA[<h1>Abstract</h1>

<blockquote><p>Cryptanalysis always gets better. It never gets worse.</p><footer><strong>NSA saying,</strong> <cite><a href='http://www.wired.com/opinion/2013/09/black-budget-what-exactly-are-the-nsas-cryptanalytic-capabilities/'>Wired</a></cite></footer></blockquote>


<p><em>Many in the public policy, defense, technology, and security
communities have long known, and Edward Snowden gave his freedom to
remind us, that the United States government is progressively
expanding a comprehensive, intrusive intelligence-gathering system &mdash;
a Panopticon with capabilities the average citizen can neither
comprehend nor resist &mdash; a system with unprecedented power for tyranny
and repression &mdash; and it will be far harder to dismantle than it was
to build. There are ways legislators, technologists, and the public
can push back, and we must do so as soon as possible to avert a terrible
future.</em></p>

<h1>Preface</h1>

<p>A few key facts to set the scene:</p>

<ul>
<li>9/11 was
<a href="http://www.pbs.org/wgbh/pages/frontline/shows/terrorism/fail/">publicly</a>
<a href="http://www.freerepublic.com/focus/news/686043/posts">labeled</a> a
<a href="http://www.realclearpolitics.com/articles/2013/09/01/our_infected_intelligence_system_119794.html">failure of intelligence</a>
by a wide cross-section of the American media and political
establishment.</li>
<li>We have a cultural need to place blame on individuals or groups for
bad events, even those that result from systemic failure.</li>
<li>The United States &mdash; hereafter &ldquo;we&rdquo;, though much of this applies to
the &ldquo;five eyes&rdquo; (viz. Australia, Canada, New Zealand, the UK, and
the US) as well &mdash; has made massive investments in &ldquo;homeland
security&rdquo; signals intelligence for a variety of purposes, including but not
limited to counter-terrorism.</li>
<li>The United States National Security Agency (NSA)
<a href="http://www.wired.com/opinion/2013/09/black-budget-what-exactly-are-the-nsas-cryptanalytic-capabilities/">probably spends more on cryptography research than everyone else put together</a>. They
publish very little research. Thus, the cutting edge
of public research is likely an inaccurate predictor of the NSA&rsquo;s
cryptologic capabilities.</li>
<li>The prospect of collateral damage does not, in practice, deter the
American intelligence apparatus from using its capabilities to
identify, capture, and kill terrorists.</li>
<li>Through Edward Snowden and others, we have significant evidence
that the NSA has spent significant effort building a comprehensive
apparatus for surveilling both Americans and foreigners. Through
the PRISM program and other systems, they have acquired
unprecedented access to the private information of citizens
worldwide. They have made significant investment in systems to
automatically analyze this data. The public does not know the full
extent of their capability in this regard.</li>
<li>The head of the NSA, Gen. Keith Alexander,
<a href="http://www.washingtonpost.com/world/national-security/for-nsa-chief-terrorist-threat-drives-passion-to-collect-it-all/2013/07/14/3d26ef80-ea49-11e2-a301-ea5a8116d211_story.html">believes</a>
that only by collecting all available data can the NSA effectively
thwart terrorism.</li>
<li>The public state of the art in data storage and analysis &mdash; storage
capacity, processing speed, statistical techniques, available
software, automation capability &mdash; is several orders of magnitude better
than it was 20 years ago. We have no reason to expect this trend
will not continue.</li>
</ul>


<h1>Where we could go</h1>

<p>Imagine you&rsquo;re the director of US
national intelligence. It&rsquo;s a few years from now, and you&rsquo;ve been given
an enormous budget and an effectively unlimited supply of smart people
to end the terrorism problem. With these resources you build <em>Deep
Thought</em> &mdash; a machine with access to an unfathomably deep database,
capable of answering arbitrarily-formed questions about the population
of the US.</p>

<p>Billions of dollars and thousands of man-years later, with the
President and the Joint Chiefs watching, you stand in front of this
machine and say,</p>

<blockquote><p>Show me the terrorists.</p></blockquote>

<p>Obligingly, Deep Thought displays a list of Islamist radicals,
anarchist cranks, would-be Unabombers, and so on. The dedicated men
and women of our national security agencies round up these dangerous
criminals and lock them away. The nation rejoices. The TSA lets you
fly with shampoo again. Everyone&rsquo;s happy.</p>

<p>There is just one catch: Deep Thought is <em>still sitting there</em>, waiting
to accept input. The nation has already sunk the cost of building it,
and it&rsquo;s not about to shut it off any more than, say, unilaterally
destroy the entire strategic nuclear arsenal. But since we <em>have it</em>:</p>

<blockquote><p>Show me the murderers.</p>

<p>Show me the child molestors.</p>

<p>Show me the kidnappers.</p></blockquote>

<p>The New York Times has a field day. Fox News runs a slide show of
missing little girls and their rabid killers, finally brought to
justice. Government approval soars.</p>

<p>And Deep Thought is still sitting there, waiting for the next question.</p>

<blockquote><p>Show me the drug dealers.</p></blockquote>

<p>Hundreds of thousands, ranging from die-hard methheads to small-time
marijuana dealers to club kids to ancient hippies passing out LSD. In
one swift stroke, the drug problem in the United States is
over. Despite the collateral damage (a few politicians&#8217; sons, how
embarrassing) support is broad.</p>

<blockquote><p>Show me anyone with the capability and intent to bring down the
United States government.</p>

<p>Show me the leakers.</p>

<p>Show me the hackers.</p></blockquote>

<p>It is still pretty easy to justify. These are dangerous people &mdash;
traitors, even. &ldquo;Crazies.&rdquo; Nobody really complains.</p>

<p>Who is left? <em>Anyone you want</em>.</p>

<blockquote><p>Show me the dissidents.</p>

<p>Show me the activists.</p>

<p>Show me&hellip;</p></blockquote>

<h2>Frequently exclaimed &ldquo;but!&#8221;s</h2>

<h3>That system you described is impossible.</h3>

<p>I agree &mdash; there&rsquo;s no way we could ever build a system with <em>zero
error rate</em>. Either we would miss some terrorists by ensuring
P(terrorist)=1 (and if you think we would take this road, I have a
<a href="https://en.wikipedia.org/wiki/Dual_EC_DRBG">deterministic random bit generator</a>
to sell you) or we would end up including innocents in the results, like
dolphins in a net of
tuna. <a href="https://en.wikipedia.org/wiki/Khalid_El-Masri">See: this guy</a>.</p>

<p>A 100%-accurate system like this is impossible with the tech we have
today. Much more likely is a system &mdash; much like ones we have today &mdash;
that gives a <em>probability</em> of being a terrorist. Unfortunately,
decision-makers aren&rsquo;t often big on fuzzy probabilities:</p>

<blockquote><p>&#8220;I don&#8217;t need this,&#8221; Harris reports that a senior CIA officer working<br/>on the agency&#8217;s drone program once told an NSA analyst who showed up<br/>with a big, nebulous graph. &#8220;I just need you to tell me whose ass to<br/>put a Hellfire missile on.&#8221;</p><footer><strong>Business Insider,</strong> <cite><a href='http://www.businessinsider.com/the-nsas-strength-may-be-biggest-weakness-2013-9'>The NSA&#8217;s Strength May Be Its Biggest Weakness</a></cite></footer></blockquote>


<h3>They might be able to do this in the future, but not now.</h3>

<p>Public companies, especially marketers and advertisers, are experts at
this sort of behavior. Web advertising companies jumping on the
big-data bandwagon have discovered Target et
al. <a href="http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?pagewanted=all&amp;_r=0">already there</a>. What
can the NSA accomplish with Google/Facebook/Comcast/Verizon/AT&amp;T&rsquo;s
knowledge of your online habits, plus their own sources? What profile
could they build of you? In theory, they can suborn your laptop, your
smartphone (a remotely-operable listening device with a location
tracker built in, great!), your landline, every Internet connection in
your house and business, your physical mail, your email, your
OnStar-enabled car, every online profile you have unless you adopt the
life of a complete paranoiac &mdash; and even then it only takes one
misstep for them to get
you. <a href="http://nakedsecurity.sophos.com/2012/12/03/john-mcafee-location-exif/">Ask John McAfee.</a></p>

<p>Certainly there are technical capabilities that are out of their reach
at this moment; that&rsquo;s why they&rsquo;re storing all the data for future
analysis. Data that currently seems inconsequential might be far less
so later. Currently-unbreakable crypto protocols (and remember, they
spend more on crypto research than the <em>entire rest of the world put
together</em>) may not be so unbreakable later. Good thing for them it&rsquo;s
all on disk.</p>

<h3>This is unconstitutional.</h3>

<p>Probably, but that hasn&rsquo;t stopped them. Their interpretation of the
law and the Constitution most likely doesn&rsquo;t match yours.</p>

<p><a href="http://cryptome.org/nsa-ussid18-80.htm#SECTION%203">The NSA doesn&rsquo;t consider automated interception and bulk analysis a &ldquo;collection&rdquo;</a>,
meaning it can build as large of a profile of you as it wants, no
approval required, as long as no human intentionally instructs it to
do so. Should it ever decide it needs approval, the Foreign
Intelligence Surveillance Court&rsquo;s
<a href="https://en.wikipedia.org/wiki/United_States_Foreign_Intelligence_Surveillance_Court#Criticism">approval rate is 99.97%</a>.</p>

<h3>We would know if this were happening.</h3>

<p>The NSA, DEA, and FBI have demonstrated willingness to lie to the
courts (through the method of
<a href="https://www.eff.org/deeplinks/2013/08/dea-and-nsa-team-intelligence-laundering">&ldquo;parallel construction&rdquo;</a>,
also known as intelligence laundering) about the source of their
information. They have repeatedly misled Congress about their
activities. They have <a href="http://www.slate.com/articles/news_and_politics/politics/2013/07/nsa_lexicon_how_james_clapper_and_other_u_s_officials_mislead_the_american.html">redefined</a> words like &ldquo;incidental,&rdquo; &ldquo;relevant,&rdquo;
and &ldquo;targeted&rdquo; in positively Clintonian fashion. They believe that the
disclosure of the existence and operation of this technical apparatus
is tantamount to treason against the United States.</p>

<p>You are free to believe, as President Obama
<a href="https://www.nytimes.com/2013/08/10/us/politics/obamas-remarks-at-a-news-conference.html?pagewanted=all">claims</a>,
that we would be having this debate even if Snowden hadn&rsquo;t done what he
did. I do not believe this.</p>

<h3>My life is not interesting enough to be surveilled (often rendered as &ldquo;I&rsquo;m too boring.&rdquo;)</h3>

<p>The background assumptions there:</p>

<ul>
<li>it costs the government some nontrivial amount to watch me, and</li>
<li>they don&rsquo;t gain anything of worth by doing so (after all, I am not a
terrorist!), so</li>
<li>it&rsquo;s not worth it to them to do so.</li>
</ul>


<p>The first assumption no longer holds.</p>

<p>Before the age of fast automated analysis, surveillance agencies were
limited by money and very expensive human time in the scope of their
surveillance. If they wanted to watch you, an actual human had to
spend time listening to you, following you, reading your physical
mail, and so on &mdash; with the associated Fourth Amendment implications,
to the degree the government followed them.</p>

<p>This is dramatically less true in an era of supercomputers and data
centers, where the entire metadata output of, say, Verizon can be
recorded by a few racks of servers. In other words, once the
infrastructure is in place, the marginal cost to the government to
surveil <em>you</em> is effectively zero, and the downside risk for failing to
surveil the right people is high. They may have more to lose by <em>not</em>
watching you than the other way around.</p>

<h3>What harm does it do? If you&rsquo;re doing nothing wrong, you have nothing to hide.</h3>

<p>No. If I have done nothing wrong, you have no reason to watch me.</p>

<blockquote><p>Just because Google, Facebook, Skype, Verizon and other companies are<br/>routinely monitored by the CIA doesn’t mean that somebody is watching<br/>you every time you order groceries online or voice-chat your sister in<br/>Seoul. It just means that they could if you gave them a reason to do<br/>so. That means you can relax – right up until the time when you want<br/>to go to a protest, or your sister does, or you support the fact that<br/>several thousand complete strangers did.</p><footer><strong>Laurie Penny,</strong> <cite><a href='http://www.newstatesman.com/politics/2013/06/if-you-live-surveillance-state-long-enough-you-create-censor-your-head'>If You Live in a Surveillance State for Long Enough, You Create a Censor in Your Head</a></cite></footer></blockquote>


<p><a href="http://www.newstatesman.com/politics/2013/06/if-you-live-surveillance-state-long-enough-you-create-censor-your-head">If you believe you are being watched (or are uncertain but think you may be), you change your behavior.</a>
You take fewer risks: the fear of <em>appearing</em> guilty, even with the
most innocent of motives, is enough to deter you from taking actions
that might appear such to a hostile audience. You watch what you
Google, you watch what you say on the phone. In small ways, your life
begins to resemble an airport security line (&ldquo;don&rsquo;t joke about bombs
&mdash; they might be listening!&rdquo;). In order to thrive, our democracy
requires that discourse. We need the ability to hold discussions
current (or future!) administrations might not like. We need to be
able to hold opinions others might detest. We need privacy to
flourish, and I do not believe we can be fully human, fully free,
without it.</p>

<h3>I don&rsquo;t care. If the government says they need it to catch terrorists, I trust them.</h3>

<p>Even with several <em>very</em> generous assumptions about the honesty,
integrity, and competence of the current administration (for whom I
voted twice, and about which enough has been said) &mdash; governments
change. We should be deeply cautious of such a powerful tool,
potentially the most powerful instrument of tyranny and oppression a
government has ever possessed, in the hands of any administration, no
matter how benign.  All it takes is one election. If the transition
from the Bush to Obama administrations has taught us anything, it&rsquo;s
that a change in party in no way necessitates a lessening of executive
power.</p>

<h1>What we can do</h1>

<p>In a very real way, we, the American people, did this to
ourselves. We built this machine out of fear and now, at least in the
short term, we are stuck with it. By demanding that <em>no</em> terrorist
attacks <em>ever</em> happen, and placing the blame on our intelligence
apparatus when they do, we have strongly incentivized the creation of a
system exactly like this.</p>

<p>In the short term, we can demand radical transparency and oversight
for our clandestine security agencies, starting with a top-to-bottom
audit from Congress&#8217; loudest complainers
(<a href="http://www.theguardian.com/world/2013/aug/16/nsa-revelations-privacy-breaches-udall-wyden">Senators Ron Wyden and Mark Udall come to mind</a>). We
can make this a campaign issue: as a society, we must accept this may
make them less effective (though who wholeheartedly accepts the
doomsaying coming from the NSA in response to the Snowden leaks?) and
that we are willing to make that tradeoff. Remember, as easy as it may
be for them to forget, our government works for us.</p>

<p>In the medium term, engineers and technologists must refuse to build
or support systems that engage in privacy- and liberty-destroying mass
surveillance. Transparency reports are a good start, but those with
the clout and resources to fight these orders must stand up and do so
&mdash; large companies, mostly, but individuals can as well. We must
establish a strong ethical basis to guide those in my profession as
we develop the technology of the future.</p>

<p>In the long term, we must dismantle the current architecture of
<a href="https://en.wikipedia.org/wiki/United_States_Foreign_Intelligence_Surveillance_Court">secret courts</a>,
<a href="https://en.wikipedia.org/wiki/National_security_letter">secret orders</a>,
and
<a href="https://en.wikipedia.org/wiki/Extraordinary_rendition">secret law enforcement</a>. As
a society we must stand up and say: <em>this is not who we are</em>. Though
it may come at a price, we demand freedom of thought and conscience
and association. We demand that our messages to our loved ones, our
health, our finances, our lives, retain the privacy the Constitution
specifically affords them. We demand what Voltaire called &ldquo;the right
most valued by all civilized men&rdquo;: to be left alone.</p>

<p><em>I would love to hear your comments; I am <a href="https://twitter.com/ternus">@ternus</a> on Twitter.</em></p>
]]></content>
    
  </entry>
  
  <entry>
    
    <title type="html"><![CDATA[Low-overhead paranoid browsing for fun and profit]]></title>
    <link href="http://adversari.es//blog/2013/07/23/paranoid-browsing-for-fun-and-profit/"/>
    
    <updated>2013-07-23T18:09:00-04:00</updated>
    <id>http://adversari.es//blog/2013/07/23/paranoid-browsing-for-fun-and-profit</id>
    
    <content type="html"><![CDATA[<p>Companies are investing more effort than ever before in tracking you online, and not just on their sites. They use the data provided by your browser to <a href="http://donttrack.us">build a profile of you</a> that can follow you across the web. In this post, I&rsquo;ll describe a suite of defensive techniques to push back against this tracking while still able to enjoy the modern web experience.</p>

<h1>Goals</h1>

<p>We have two goals:</p>

<ul>
<li>Leak as little information as possible to the sites you visit, while</li>
<li>Minimize impact to regular browsing behavior as much as possible.</li>
</ul>


<h1>Techniques</h1>

<h2>Use an anonymizing VPN</h2>

<p>I use <a href="https://www.privateinternetaccess.com/">Private Internet Access</a> which is $40/year, but there are a number of great options, including self-setup VPNs. All my web traffic flows through them, thus denying sites I visit the opportunity to discriminate based on my IP address &mdash; perhaps the easiest way for sites to track you.</p>

<p>Your IP address can be used to geolocate you with an astonishing degree of precision. If you&rsquo;re serious about privacy, be sure to use a VPN. You&rsquo;ll also want to enable the option that disconnects your network when the VPN isn&rsquo;t connected to prevent accidentally using an unencrypted connection.</p>

<h2>Use Firefox</h2>

<p>I love Google Chrome, and it&rsquo;s been very difficult for me to switch &mdash; but using a browser provided by a company whose business model centers around compiling as precise a profile of you as possible is no longer compatible with the goals I outlined above. An excellent example of this is how the default configuration reports a heap of data to Google, while burying the &ldquo;do not track&rdquo; setting (which Chrome was the last browser to implement) in &ldquo;advanced settings&rdquo; and giving you a warning if you enable it.</p>

<p>I hadn&rsquo;t used Firefox in years before I switched, but it&rsquo;s gotten a lot better. In particular, I&rsquo;m using the <a href="https://people.mozilla.com/~jwein/ux-nightly/">UX build</a> (warning: <em>very</em> beta), which has a Chrome-like interface.</p>

<h3>Firefox Settings</h3>

<p>It&rsquo;s easy to tune Firefox to maximize your privacy without diminishing your experience.</p>

<h4>Privacy</h4>

<p>Under the &ldquo;Privacy&rdquo; tab in the preferences page, select &ldquo;Tell sites I do not want to be tracked.&rdquo; Of course, sites are under no obligation to obey this flag, but it doesn&rsquo;t hurt to make our preferences clear.</p>

<p>Set the history preference to &ldquo;Use custom settings for history,&rdquo; change &ldquo;Accept third-party cookies&rdquo; to &ldquo;Never.&rdquo; I&rsquo;ll let CNET <a href="http://howto.cnet.com/8301-11310_39-20042703-285/disable-third-party-cookies-in-ie-firefox-and-google-chrome/">explain why</a>:</p>

<blockquote><p> So if third-party cookies offer no direct benefit to users and can potentially be a threat, why do all the major browser makers default to allowing sites to leave all the cookies they want on your machine? Because the advertisers are their customers and are at least as important to them as users are.</p></blockquote>

<p>Continue accepting cookies in general, though. We&rsquo;ll get to why that&rsquo;s OK later.</p>

<h4>Security</h4>

<p>Uncheck &ldquo;Remember passwords for sites.&rdquo; We have a better option.</p>

<h4>Search Engine</h4>

<p>I tried switching to <a href="https://duckduckgo.com">DuckDuckGo</a> but found that after nearly 1.5 decades of using Google the search quality was much poorer. (For example, when searching for the UX build link above, I searched for &ldquo;firefox UX&rdquo;, &ldquo;firefox UX build&rdquo;, &ldquo;firefox UX nightly&rdquo; etc. on DuckDuckGo, none of which produced the result I wanted. One search on Google and the first result was correct.)</p>

<p>If you want a more privacy-respecting engine than Google but can&rsquo;t give up (most of) Google&rsquo;s search quality, use <a href="https://startpage.com">Startpage</a>. This site uses Google as a backend for search results.</p>

<h4>Block Referer [sic] Header</h4>

<p>Type &ldquo;about:config&rdquo; in the address bar, then type &ldquo;referer&rdquo; in the search bar. You want to set the <code>network.http.sendRefererHeader</code> value to 0, which will prevent the browser from sending <code>Referer:</code> headers. When clicking on a link from page A to B, this will prevent B from seeing the URL of A.</p>

<h2>Firefox Addons</h2>

<p>Here are some low-impact extensions that can drastically improve your privacy.</p>

<h3><a href="https://lastpass.com">LastPass</a></h3>

<p>Fun fact: I don&rsquo;t actually know the vast majority of my passwords. LastPass is a cross-platform (Windows/Mac/Linux/Android/iOS) password manager that generates and securely stores passwords and form-fill info. It uses client-side encryption to protect your data and allows auto-login and auto-fill. Highly recommended.</p>

<h3><a href="https://www.eff.org/https-everywhere">HTTPS Everywhere</a></h3>

<p>Automatically and silently redirects you to HTTPS on many popular sites. Easy. This is how the web should work.</p>

<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/self-destructing-cookies/">Self-Destructing Cookies</a></h3>

<p>Deletes cookies for a site as soon as you close the tab. You&rsquo;ll want to whitelist sites you want to stay logged into, but this is a one-time operation per site. This can go a long, long way towards preventing sites from building a profile of you. This gets you most of the benefit of disabling cookies while still allowing you to log in.</p>

<h3><a href="https://adblockplus.org/en/firefox">Adblock Plus</a></h3>

<p>Blocks ads, and more importantly, the request to third-party sites those ads generate.</p>

<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/betterprivacy/">BetterPrivacy</a></h3>

<p>Has just one purpose: to disable LSOs (locally stored objects), a type of &ldquo;super-cookie&rdquo; used by Flash.</p>

<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/ghostery/">Ghostery</a></h3>

<p>Blocks a wide range of tracking methods 99% non-intrusively. The default configuration gives you a little popup at the upper right of your browser, which is occasionally interesting (&ldquo;I had no idea this page felt the need to track me in 12 different ways&rdquo;). Will occasionally break a page in a non-obvious way (&ldquo;I feel like there should be comments here&hellip;&rdquo;) but it&rsquo;s easy to disable temporarily if reading internet comments is your thing. <em>cough</em></p>

<h3><a href="https://www.dephormation.org.uk/index.php?page=81">Secret Agent</a></h3>

<p>Cookies aren&rsquo;t the only way sites fingerprint your browser &mdash; one of the most common methods is the user-agent string. This extension randomizes the user-agent string sent along with your browser on every request, thus spreading your information among a number of different profiles and making you harder to track. It&rsquo;ll also randomize the HTTP Accept headers.</p>

<p>Unfortunately, the default user-agent list Secret Agent ships with causes problems with sites as their capability-detection mechanisms go haywire (Lynx?!). I&rsquo;ve created my own <a href="http://adversari.es/assets/useragentlist.txt">list of modern user agents</a> consisting of the most popular browser strings from Firefox, Chrome, and Safari.</p>

<h3><a href="https://addons.mozilla.org/en-US/firefox/addon/flashblock/">Flashblock</a></h3>

<p>Disallows Flash from running by default, replacing Flash applets with a placeholder that runs the applet when clicked. Not only does this protect against malicious (or annoying!) Flash apps, it&rsquo;ll prevent browsers from using Flash-based fingerprinting methods (such as loading the list of installed fonts). I&rsquo;ve used click-to-run on Google Chrome for ages and it&rsquo;s been great.</p>

<h1>Out of Scope</h1>

<p>There are a number of extensions and options not included here, largely because they have too significant of an impact on regular day-to-day browsing. <strong>Tor</strong> slows down browsing far too much. <strong>NoScript</strong> and <strong>RequestPolicy</strong> require user intervention on virtually every page in order to load properly.</p>

<h1>Conclusion</h1>

<p>You can see the impact of some of these techniques using <a href="https://panopticlick.eff.org">Panopticlick</a>. If your browser is unique, don&rsquo;t worry &mdash; just check how it changes on each reload, which Secret Agent should help with.</p>

<p>These techniques should allow you to browse the web with greater confidence that companies aren&rsquo;t tracking you everywhere you go.</p>

<p><em>Got any other suggestions for low-impact privacy improvements? Tweet me at <a href="https://twitter.com/ternus">@ternus</a>.</em></p>
]]></content>
    
  </entry>
  
  <entry>
    
    <title type="html"><![CDATA[Infosec's Jerk Problem]]></title>
    <link href="http://adversari.es//blog/2013/06/19/cant-we-all-just-get-along/"/>
    
    <updated>2013-06-19T14:59:00-04:00</updated>
    <id>http://adversari.es//blog/2013/06/19/cant-we-all-just-get-along</id>
    
    <content type="html"><![CDATA[<p>Put bluntly: to others, we&rsquo;re jerks.</p>

<p>If you don&rsquo;t think this is a problem, you can stop reading here.</p>

<h3>The dysfunctional tale of Bob and Alice</h3>

<p>Imagine this. Developer Bob just received an email from your Infosec
department, subject <em>Important Security Update.</em> He sighs, thinking of the
possibilities: a request to rotate his password, or a new rule? Maybe it&rsquo;s a
dressing-down for having violated some policy, a demand for extra work to
patch a system, or yet another hair-on-fire security update he doesn&rsquo;t
really see the need for. His manager is on his case: he&rsquo;s been
putting in long hours on the next rev of the backend but library
incompatibilities and inconsistent APIs have ruined his week, and he&rsquo;s way
behind schedule. He shelves the security update &mdash; he doesn&rsquo;t have time to
deal with it, and most things coming out of Infosec are just sound and fury
anyway &mdash; and, thinking how nice it would be if his team actually got the
resources it needed, continues to code. He&rsquo;ll get to it later. Promise.</p>

<p>Meanwhile, you, Security Researcher Alice, are trying not to panic. You&rsquo;ve
seen the latest Rails vulnerability disclosure, and you know it&rsquo;s just a
matter of hours before your exposed system gets hit. You remember
what happened to <a href="http://www.h-online.com/open/news/item/GitHub-security-incident-highlights-Ruby-on-Rails-problem-1463207.html">Github</a> and <a href="https://blog.heroku.com/archives/2013/1/11/rails_security_vulnerability">Heroku</a>, and you&rsquo;re not anxious to make the front
page of Hacker News (again?!). If only Bob would answer his email! You know
he&rsquo;s at work &mdash; what&rsquo;s happening? The face of your boss the last time your
software got exploited appears in your mind, and you cringe, dreading an
unpleasant meeting ahead. You fume for several minutes, cursing all developers everywhere, but no response is forthcoming. Angrily, you stand up and march over to
his cube, ready to give him a piece of your mind.</p>

<p>Pause. What&rsquo;s going on here, and what&rsquo;s about to happen?</p>

<h3>Interlude: we are the watchers on the walls</h3>

<p>Many in the Infosec community are fond of casting the security world as &ldquo;us
versus them,&rdquo; where &ldquo;they&rdquo; aren&rsquo;t external, malicious actors but
unaware users, clueless managers, and bumbling executives within our own
organizations. <strong>We like to see ourselves as the <a href="http://awoiaf.westeros.org/index.php/Night's_Watch">Night&rsquo;s
Watch</a> of the tech
world</strong>: out in the cold with little love or support, putting in long nights
protecting the realm against the real threats (which the pampered never take
seriously) so everyone else can get on with their lives in comfort. We develop
a jaundiced attitude: only we understand the real danger, we think, and while
we&rsquo;re doing our best to stave off outsider threats, when the long night comes
we need fast and unquestioning cooperation from the rest of the organization
lest (hopefully metaphorical) frozen undead kill us all.</p>

<p>The rest of the organization doesn&rsquo;t see it that way. <strong>To them,
we&rsquo;re Chicken Little crossed with the IRS crossed with their least favorite
elementary-school teacher</strong>: always yelling about the sky falling, demanding
unquestioning obedience to a laundry list of arcane, seemingly arbitrary rules
(<a href="http://www.csoandy.com/files/password_weakness.html">password complexity requirements</a>, anyone?) that seem of little consequence,
and condescendingly remonstrating anyone who steps out of line. Once in a
while a visionary (often an Infosec expat) who truly understands the threat
tries to help others see the value, but most of &ldquo;them&rdquo; don&rsquo;t get it. <em>Users are
stupid. Managers are idiots. Executives are out of touch.</em> So it goes.</p>

<h3>Back to the story</h3>

<p>From Bob&rsquo;s perspective, he&rsquo;s making a reasonable risk/reward tradeoff: not
dealing with the email right now might get him yelled at, but judging from
history, probably not &mdash; he gets lots of &ldquo;urgent&rdquo; security emails that turn
out to be Windows patches, admonitions to change his password, policy
reminders and so on. From your perspective, Bob is being completely
irresponsible: you told him it was important; it was right there in the
subject line!</p>

<p>You storm into Bob&rsquo;s cubicle. Images of mocking Hacker News articles dancing
in your head, you accuse Bob of flagrant negligence (perhaps letting out some
anger over the last security incident; Bob works on that team, doesn&rsquo;t he?)
and demand that he drop whatever he&rsquo;s doing and fix this, <em>now</em>. This mood of
righteous indignation doesn&rsquo;t lend itself to patient explanations, and Bob&rsquo;s
demand that you explain the vulnerability is met with your impatient demand to
&ldquo;just do it.&rdquo; There isn&rsquo;t time for that &mdash; someone could be dumping your
database as you speak!</p>

<p>Bob, already running out of patience due to his looming deadline, fires back
that he <em>can&rsquo;t</em> deal with this now, he&rsquo;s too busy, it&rsquo;s not his problem (there
are other devs, right?) and you should take it up with his manager. Even if he
could, he wouldn&rsquo;t: didn&rsquo;t the last few Infosec red alerts turn out to be
nothing? Why are you trying to waste his time? Don&rsquo;t you understand he has
real work to do, work he&rsquo;ll get fired for not doing?</p>

<p>Bob considers this a horrendous distraction from his critical dev
work, and you see Bob as dragging his feet while the building&rsquo;s on fire. You
both walk away angry. Regardless of whether the vulnerability eventually gets closed, serious harm has been done.</p>

<p>A common, less overtly contentious version of this exchange involves <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt">FUD</a> on both ends,
with vague yet ominous threats coming from Infosec and a haze of scheduling
delays, configuration problems, and blaming other teams (QA being a favorite)
from the dev team. This usually gets management involved and everyone has a bad day.</p>

<p>There are two problems here. The first is a lack of understanding, the second,
a lack of empathy.</p>

<h3>Understanding is a three-edged sword: our side, their side, and the truth</h3>

<p><a href="http://www.swlearning.com/economics/mankiw/principles2e/principles.html">Mankiw&rsquo;s Principles of Economics</a>
apply here, particularly the first and fourth: &ldquo;People face
tradeoffs&rdquo; and &ldquo;People respond to incentives.&rdquo;
Hanlon&rsquo;s Razor says &ldquo;Never attribute to malice that which can be adequately
explained by incompetence,&rdquo; but I would add, <strong>&ldquo;Never attribute to incompetence
that which can be explained by differing incentive structures.&rdquo;</strong></p>

<p>For example:</p>

<ul>
<li>Tradeoffs: if you give someone two tasks, both of which could take up 75% of their time, then tell them they will be fired if they don&rsquo;t do Task A, don&rsquo;t be surprised when Task B doesn&rsquo;t get done.</li>
<li>Positive incentives: if you measure QA performance by number of bugs found, you&rsquo;ll find dozens of spurious bugs in the system.</li>
<li>Negative incentives: measure developer performance by number of bugs generated and watch as devs pressure QA to not consider problems &ldquo;bugs.&rdquo;</li>
<li>&ldquo;Never argue with a man whose job depends on not being convinced.&rdquo; &mdash; H.L. Mencken</li>
</ul>


<p>These problems are not amenable to the sort of frontal assault described
above. That approach assumes the target doesn&rsquo;t understand or isn&rsquo;t aware of
the problem, while in many cases they fully are. While yelling at someone may
occasionally achieve the result you want, it doesn&rsquo;t come without collateral
damage, including massive loss of goodwill. Sometimes hard authority
(executive fiat) is the only way to get the job done, but usually there&rsquo;s a
better way.</p>

<p>Imagine a group of people invite you and your friends to a local football
field to play a friendly game. You show up and are quickly bewildered: the
others are mocking you, nothing seems to be going the way it should, and when
one of them shouts &ldquo;go!&rdquo; some of your friends are injured in the ensuing
confusion. You could shout at your newfound acquaintances for hurting your
friends, complain privately about how stupid they are for not understanding
the rules&hellip; or pause for a moment, collect the available facts, and realize
that <em>they had actually invited you to play rugby</em>. Disregarding your goals
and charging off in another direction is not necessarily an indicator of
malice <em>or</em> stupidity.  <strong>People are always playing a different game &mdash; it just
occasionally has similar rules to yours.</strong></p>

<p>Developers are measured on their ability to get software out the door. QA
teams are often measured on speed. Managers are responsible for the
performance of their team. Executives worry about the overall direction of the
business. <em>You need to show how security aligns with these goals</em>. Security
can be more than just a hedge against long-term downside risk: it can be a way
for everyone to produce better software.</p>

<p>What you need to understand is others&#8217; <strong>value calculus</strong>: what factors go
into what they consider important? Given that, how can you both decide on some
security goals that are in line with both their calculus and yours?</p>

<h3>Empathy</h3>

<p>The jaundiced attitude among Infosec mentioned above, coupled with differing
incentive structures, has an unfortunate tendency to spill over into external
interactions. If 90% of lunch conversations are complaints about how terrible
users are, how management doesn&rsquo;t get it, and how the dev team on Project Foo
are a bunch of incompetent turd-burglars &mdash;&ndash; the next time you have to meet
with Project Foo&rsquo;s team, you&rsquo;ll be hard-pressed to give them a fair hearing as
they explain how their lack of proper resources and mountain of technical debt
prevent them from addressing problems properly.</p>

<p>When we go for the easy answers:</p>

<blockquote><p>This {<em>system, product, device, network</em>}
is {<em>insecure, vulnerable, unsafe, slow, broken, unprofitable, incomplete, poorly designed, ugly</em>}
because the {<em>designer, manager, dev team, executives, QA, sales</em>}
{<em>is incompetent, is lazy, doesn&rsquo;t care about security, is an asshat</em>}</p></blockquote>

<p>we erode our ability to evaluate the true cause of a situation. (Social
psychology refers to this as the <a href="https://en.wikipedia.org/wiki/Fundamental_attribution_error">Fundamental Attribution Error</a> &mdash; the
tendency to attribute others&#8217; mistakes to their inherent failings, while
attributing our own mistakes to the situation at hand.) We damage our reputation (and that of Infosec as a field), make ourselves
unpleasant to deal with, and generally make the world a worse place.</p>

<p>We also get used to thinking of people and teams in that way. We genuinely become less kind people.</p>

<h2>What&rsquo;s the alternative?</h2>

<p><em>Practice active kindness.</em> Go out of your way to do kind things for people,
<em>especially</em> people who may not deserve it. If you wait for them to make the
first move, you&rsquo;ll be waiting a while &mdash; but extend a hand to someone who
expects a kick in the teeth and watch as you gain a new friend. Smile.</p>

<p><em>Don&rsquo;t go for the easy, wrong answers.</em> That team isn&rsquo;t incompetent, they just
have too much work to do; how can we work with them to get our thing done?
That manager isn&rsquo;t stonewalling, he just has a different incentive structure
&mdash; how can we understand what it is?</p>

<p><em>Seek to understand and make this clear.</em> When asking someone to do
something, try to understand their current situation first. Perhaps the
request isn&rsquo;t as urgent as all that &mdash; but say it is. &ldquo;I know you have a lot
on your plate, with the X deadline and the Y update, but public-facing system
Z could be compromised.&rdquo; Ask questions and listen to the answers.</p>

<p><em>Be flexible. Recalibrate &ldquo;urgent.&rdquo;</em> Think of the worst possible thing that
could happen to your organization. Now try to make it worse. I&rsquo;ve worked in
places where the worst-case scenario involves &ldquo;loss of multiple human lives.&rdquo;
Will the world end if this minor security patch isn&rsquo;t applied today? Think of
the automated OS updates popping up in the corner of your screen: how often
are those more important than what you&rsquo;re doing? If you practice this and do
it well, people will start to feel you understand their value calculus, and
this makes them much more likely to take your advice.</p>

<p><em>Create stakeholders and spread security knowledge.</em> One thing our Infosec
team tries to do is have people create their own security goals. The answer to
&ldquo;what does it mean to be safe&rdquo; ultimately is up to them; we just guide the
process. This means <em>they&rsquo;re invested in security</em> &ndash; the more they&rsquo;ve thought
about the safety of their own product, the more likely they are to value it as
a goal.</p>

<h2>Conclusion</h2>

<p>Fixing Infosec&rsquo;s jerk problem benefits everyone: us, the people we deal with,
and ultimately the security of the system &mdash; and since that&rsquo;s our long-term
goal, we should actively seek to fix the problem. <strong>Be kind, and the rest will
follow.</strong></p>

<p><em>What do you think? Let me know on Twitter; I&rsquo;m <a href="https://twitter.com/ternus">@ternus</a>.</em></p>
]]></content>
    
  </entry>
  
</feed>